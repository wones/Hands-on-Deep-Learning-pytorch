{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clinical-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-windows",
   "metadata": {},
   "source": [
    "### 创建Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-truck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.9082e-39, 9.8265e-39, 9.4592e-39],\n",
      "        [1.0561e-38, 1.0653e-38, 1.0469e-38],\n",
      "        [9.5510e-39, 1.0378e-38, 8.9082e-39],\n",
      "        [9.6429e-39, 8.9082e-39, 9.1837e-39],\n",
      "        [1.0010e-38, 1.0286e-38, 1.6956e-43]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个5*3的未初始化的Tensor\n",
    "x=torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blind-cornwall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9088, 0.1529, 0.2951],\n",
      "        [0.9579, 0.1178, 0.8992],\n",
      "        [0.6120, 0.4657, 0.9614],\n",
      "        [0.5849, 0.8409, 0.9280],\n",
      "        [0.7214, 0.4049, 0.8886]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个5*3的随机初始化的Tensor\n",
    "x=torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "independent-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个5*3的long型全0的Tensor\n",
    "x=torch.zeros(5,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "union-palmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "#根据数据创建\n",
    "x=torch.tensor([5.5,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continuing-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.6400,  1.1500, -0.6813],\n",
      "        [-1.8840, -0.4631, -0.5259],\n",
      "        [-1.9029,  0.0992,  0.6612],\n",
      "        [-0.2438, -1.1222,  0.3006],\n",
      "        [-1.8822,  1.3868, -2.3430]])\n"
     ]
    }
   ],
   "source": [
    "#根据现有Tensor创建\n",
    "x=x.new_ones(5,3,dtype=torch.float64)\n",
    "print(x)\n",
    "x=torch.randn_like(x,dtype=torch.float)#指定新的数据类型\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "discrete-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "#通过shape或者size()来获取Tensor的形状\n",
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-asthma",
   "metadata": {},
   "source": [
    "### 操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-pound",
   "metadata": {},
   "source": [
    "算术操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "initial-slide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5871,  1.4559, -0.6118],\n",
      "        [-1.5011,  0.1294, -0.3774],\n",
      "        [-1.2871,  0.1029,  0.9082],\n",
      "        [ 0.2695, -1.0141,  1.2886],\n",
      "        [-1.6873,  1.9408, -1.3522]])\n"
     ]
    }
   ],
   "source": [
    "#加一\n",
    "y=torch.rand(5,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "extended-yahoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5871,  1.4559, -0.6118],\n",
      "        [-1.5011,  0.1294, -0.3774],\n",
      "        [-1.2871,  0.1029,  0.9082],\n",
      "        [ 0.2695, -1.0141,  1.2886],\n",
      "        [-1.6873,  1.9408, -1.3522]])\n",
      "tensor([[-0.5871,  1.4559, -0.6118],\n",
      "        [-1.5011,  0.1294, -0.3774],\n",
      "        [-1.2871,  0.1029,  0.9082],\n",
      "        [ 0.2695, -1.0141,  1.2886],\n",
      "        [-1.6873,  1.9408, -1.3522]])\n"
     ]
    }
   ],
   "source": [
    "#加二\n",
    "print(torch.add(x,y))\n",
    "\n",
    "#还可以指定输出\n",
    "result=torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "active-testament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5871,  1.4559, -0.6118],\n",
      "        [-1.5011,  0.1294, -0.3774],\n",
      "        [-1.2871,  0.1029,  0.9082],\n",
      "        [ 0.2695, -1.0141,  1.2886],\n",
      "        [-1.6873,  1.9408, -1.3522]])\n"
     ]
    }
   ],
   "source": [
    "#加三 inplace\n",
    "#adds x to y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-reserve",
   "metadata": {},
   "source": [
    "索引  \n",
    "    我们还可以使⽤类似NumPy的索引操作来访问 Tensor 的⼀部分，需要注意的是：索引出来的结果与原数据共享内存，也即修改⼀个，另⼀个会跟着修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cleared-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3600, 3.1500, 1.3187])\n",
      "tensor([2.3600, 4.1500, 2.3187])\n",
      "tensor([2.3600, 4.1500, 2.3187])\n"
     ]
    }
   ],
   "source": [
    "y=x[0,:]\n",
    "print(y)\n",
    "y+=1\n",
    "print(y)\n",
    "print(x[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-shaft",
   "metadata": {},
   "source": [
    "改变形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "compressed-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\n",
      "tensor([[ 3.3600,  5.1500,  3.3187],\n",
      "        [-0.8840,  0.5369,  0.4741],\n",
      "        [-0.9029,  1.0992,  1.6612],\n",
      "        [ 0.7562, -0.1222,  1.3006],\n",
      "        [-0.8822,  2.3868, -1.3430]])\n",
      "tensor([ 3.3600,  5.1500,  3.3187, -0.8840,  0.5369,  0.4741, -0.9029,  1.0992,\n",
      "         1.6612,  0.7562, -0.1222,  1.3006, -0.8822,  2.3868, -1.3430])\n",
      "tensor([[ 3.3600,  5.1500,  3.3187, -0.8840,  0.5369],\n",
      "        [ 0.4741, -0.9029,  1.0992,  1.6612,  0.7562],\n",
      "        [-0.1222,  1.3006, -0.8822,  2.3868, -1.3430]])\n"
     ]
    }
   ],
   "source": [
    "y=x.view(15)\n",
    "z=x.view(-1,5) #-1所指的维度可以根据其他维度的值推出来\n",
    "print(x.size(),y.size(),z.size())\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "better-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.3600,  6.1500,  4.3187],\n",
      "        [ 0.1160,  1.5369,  1.4741],\n",
      "        [ 0.0971,  2.0992,  2.6612],\n",
      "        [ 1.7562,  0.8778,  2.3006],\n",
      "        [ 0.1178,  3.3868, -0.3430]])\n",
      "tensor([ 4.3600,  6.1500,  4.3187,  0.1160,  1.5369,  1.4741,  0.0971,  2.0992,\n",
      "         2.6612,  1.7562,  0.8778,  2.3006,  0.1178,  3.3868, -0.3430])\n",
      "tensor([[ 4.3600,  6.1500,  4.3187,  0.1160,  1.5369],\n",
      "        [ 1.4741,  0.0971,  2.0992,  2.6612,  1.7562],\n",
      "        [ 0.8778,  2.3006,  0.1178,  3.3868, -0.3430]])\n"
     ]
    }
   ],
   "source": [
    "#view()返回的新tensor与源tensor共享内存，即改变其中一个，另外一个也会跟着改变。\n",
    "x+=1\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "stunning-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.3600,  5.1500,  3.3187],\n",
      "        [-0.8840,  0.5369,  0.4741],\n",
      "        [-0.9029,  1.0992,  1.6612],\n",
      "        [ 0.7562, -0.1222,  1.3006],\n",
      "        [-0.8822,  2.3868, -1.3430]])\n",
      "tensor([ 4.3600,  6.1500,  4.3187,  0.1160,  1.5369,  1.4741,  0.0971,  2.0992,\n",
      "         2.6612,  1.7562,  0.8778,  2.3006,  0.1178,  3.3868, -0.3430])\n"
     ]
    }
   ],
   "source": [
    "#返回一个副本\n",
    "x_cp=x.clone().view(15)\n",
    "x-=1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "sorted-saturn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0136])\n",
      "0.013601233251392841\n"
     ]
    }
   ],
   "source": [
    "#item()函数，可以将标量tensor转换成一个python number\n",
    "x=torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-attraction",
   "metadata": {},
   "source": [
    "广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-closing",
   "metadata": {},
   "source": [
    "运算的内存开销"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-state",
   "metadata": {},
   "source": [
    "TENSOR 和 NUMPY 相互转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-valley",
   "metadata": {},
   "source": [
    "TENSOR ON GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-entrance",
   "metadata": {},
   "source": [
    "### 自动求梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-culture",
   "metadata": {},
   "source": [
    "Tensor 是这个包的核⼼类，如果将其属性 .requires_grad 设置为 True ，它将开始追\n",
    "踪(track)在其上的所有操作（这样就可以利⽤链式法则进⾏梯度传播了）。完成计算后，可以调\n",
    "⽤ .backward() 来完成所有梯度计算。此 Tensor 的梯度将累积到 .grad 属性中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "introductory-apparatus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#创建一个Tensor并设置 requires_grad=true\n",
    "x=torch.ones(2,2,requires_grad=True)\n",
    "print(x)\n",
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "light-level",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000002A73041FAC0>\n"
     ]
    }
   ],
   "source": [
    "y=x+2\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "national-bloom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "#像x这种直接创建的称为叶⼦节点，叶⼦节点对应的 grad_fn 是 None \n",
    "print(x.is_leaf,y.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "according-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y*3\n",
    "out=z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "chicken-somerset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000002A7311F2CA0>\n"
     ]
    }
   ],
   "source": [
    "#通过 .requires_grad_() 来⽤in-place的⽅式改变 requires_grad 属性：\n",
    "a=torch.randn(2,2) # 缺失情况下默认 requires_grad = False\n",
    "a=((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b=(a*a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "metallic-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为 out 是⼀个标量，所以调⽤ backward() 时不需要指定求导变量：\n",
    "out.backward()  # 等价于 out.backward(torch.tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "failing-speaker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "typical-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.5000, 5.5000],\n",
      "        [5.5000, 5.5000]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "out2=x.sum()\n",
    "out2.backward()\n",
    "print(x.grad)\n",
    "\n",
    "out3=x.sum()\n",
    "x.grad.data.zero_()\n",
    "out3.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "smoking-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1.0,2.0,3.0,4.0],requires_grad=True)\n",
    "y=2*x\n",
    "z=y.view(2,2)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "accompanied-surface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "#现在 y 不是⼀个标量，所以在调⽤ backward 时需要传⼊⼀个和 y 同形的权᯿向量进⾏加权求和得到⼀个标量。\n",
    "v=torch.tensor([[1.0,1.0],[1.0,1.0]],dtype=torch.float)\n",
    "z.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "second-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor(1., grad_fn=<PowBackward0>) True\n",
      "tensor(1.) False\n",
      "tensor(2., grad_fn=<AddBackward0>) True\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.0,requires_grad=True)\n",
    "y1=x**2\n",
    "with torch.no_grad():\n",
    "    y2=x**3\n",
    "y3=y1+y2\n",
    "print(x.requires_grad)\n",
    "print(y1,y1.requires_grad)\n",
    "print(y2,y2.requires_grad)\n",
    "print(y3,y3.requires_grad)\n",
    "y3.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "progressive-clone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "False\n",
      "tensor([100.], requires_grad=True)\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(1,requires_grad=True)\n",
    "print(x.data)\n",
    "print(x.data.requires_grad)\n",
    "\n",
    "y=2*x\n",
    "x.data *=100\n",
    "y.backward()\n",
    "print(x)\n",
    "print(x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
