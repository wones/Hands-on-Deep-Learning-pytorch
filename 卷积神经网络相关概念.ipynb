{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b11f99",
   "metadata": {},
   "source": [
    "# 二维卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1048d05b",
   "metadata": {},
   "source": [
    "## 二维互相关运输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deebe8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def corr2d(X,K):\n",
    "    h,w=K.shape\n",
    "    Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6aa6da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
    "K=torch.tensor([[0,1],[2,3]])\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc24254",
   "metadata": {},
   "source": [
    "## 二维卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2395de",
   "metadata": {},
   "source": [
    "⼆维卷积层将输⼊和卷积核做互相关运算，并加上⼀个标量偏差来得到输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7a9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super(Conv2D,self).__init__()\n",
    "        self.weight=nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias=nn.Parameter(torch.randn(1))\n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight)+self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19246f",
   "metadata": {},
   "source": [
    "## 图像中物体边缘检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebbe9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.ones(6,8)\n",
    "X[:,2:6]=0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fddcae54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=torch.tensor([[1,-1]])\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e319461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=corr2d(X,K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921e289",
   "metadata": {},
   "source": [
    "## 通过数据学习核数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d54889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,loss 11.466\n",
      "Step 10,loss 3.169\n",
      "Step 15,loss 0.880\n",
      "Step 20,loss 0.245\n"
     ]
    }
   ],
   "source": [
    "conv2d=Conv2D(kernel_size=(1,2))\n",
    "step=20\n",
    "lr=0.01\n",
    "for i in range(step):\n",
    "    Y_hat=conv2d(X)\n",
    "    l=((Y_hat-Y)**2).sum()\n",
    "    l.backward()\n",
    "    \n",
    "    conv2d.weight.data-=lr*conv2d.weight.grad\n",
    "    conv2d.bias.data-=lr*conv2d.bias.grad\n",
    "    \n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.grad.fill_(0)\n",
    "    if (i+1)%5==0:\n",
    "        print('Step %d,loss %.3f'%(i+1,l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f08327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: tensor([[ 0.8764, -0.8724]])\n",
      "bias: tensor([-0.0022])\n"
     ]
    }
   ],
   "source": [
    "print('weight:',conv2d.weight.data)\n",
    "print('bias:',conv2d.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24574826",
   "metadata": {},
   "source": [
    "## 互相关运算和卷积运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4bcb7",
   "metadata": {},
   "source": [
    "卷积层为何能使⽤互相关运算替代卷积运算。其实，在深度学习中核数组都是学出\n",
    "来的：卷积层⽆论使⽤互相关运算或卷积运算都不影响模型预测时的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512111ad",
   "metadata": {},
   "source": [
    "## 特征图和感受野"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba93f95",
   "metadata": {},
   "source": [
    "⼆维卷积层输出的⼆维数组可以看作是输⼊在空间维度（宽和⾼）上某⼀级的表征，也叫特征图\n",
    "（feature map）。影响元素x的前向计算的所有可能输⼊区域（可能⼤于输⼊的实际尺⼨）叫做x的\n",
    "感受野（receptive field）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325e521",
   "metadata": {},
   "source": [
    "可⻅，我们可以通过更深的卷积神经⽹络使特征图中单个元素的\n",
    "感受野变得更加⼴阔，从⽽捕捉输⼊上更⼤尺⼨的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e292c6f",
   "metadata": {},
   "source": [
    "# 填充和步幅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11c207",
   "metadata": {},
   "source": [
    "## 填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89868f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def comp_conv2d(conv2d,X):\n",
    "    X=X.view((1,1)+X.shape)\n",
    "    Y=conv2d(X)\n",
    "    return Y.view(Y.shape[2:])\n",
    "\n",
    "# 注意这⾥是两侧分别填充1⾏或列，所以在两侧⼀共填充2⾏或列\n",
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,padding=1)\n",
    "X=torch.rand(8,8)\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d6465",
   "metadata": {},
   "source": [
    "当卷积核的⾼和宽不同时，我们也可以通过设置⾼和宽上不同的填充数使输出和输⼊具有相同的⾼和\n",
    "宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc372fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfa6118",
   "metadata": {},
   "source": [
    "## 步幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0a4000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72af7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097882d",
   "metadata": {},
   "source": [
    "# 多输入通道和多输出通道"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7cb31a",
   "metadata": {},
   "source": [
    "## 多输入通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "616dbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "\n",
    "def corr2d(X,K):\n",
    "    h,w=K.shape\n",
    "    Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y\n",
    "\n",
    "def corr2d_multi_in(X,K):\n",
    "    res=corr2d(X[0,:,:],K[0,:,:])\n",
    "    for i in range(1,X.shape[0]):\n",
    "        res+=corr2d(X[i,:,:],K[i,:,:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97ad64fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor([[[0,1,2],[3,4,5],[6,7,8]],[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "K=torch.tensor([[[0,1],[2,3]],[[1,2],[3,4]]])\n",
    "corr2d_multi_in(X,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb846e",
   "metadata": {},
   "source": [
    "## 多输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a57c1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X,K):\n",
    "    return torch.stack([corr2d_multi_in(X,k) for k in K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d533488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=torch.tensor([[[0,1],[2,3]],[[1,2],[3,4]]])\n",
    "K=torch.stack([K,K+1,K+2])\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7520019c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f039f",
   "metadata": {},
   "source": [
    "## 1X1卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafec5e4",
   "metadata": {},
   "source": [
    "假设我们将通道维当作特征维，将⾼和宽维度上的元素当成数据样本，那么1x1卷积层的作⽤与全连接层等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f173469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X,K):\n",
    "    c_i,h,w=X.shape\n",
    "    c_o=K.shape[0]\n",
    "    X=X.view(c_i,h*w)\n",
    "    K=K.view(c_o,c_i)\n",
    "    Y=torch.mm(K,X)#全连接层的矩阵乘法\n",
    "    return Y.view(c_o,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a1f587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.rand(3,3,3)\n",
    "K=torch.rand(2,3,1,1)\n",
    "Y1=corr2d_multi_in_out_1x1(X,K)\n",
    "Y2=corr2d_multi_in_out(X,K)\n",
    "print(Y1.shape)\n",
    "(Y1-Y2).norm().item()<1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8ecd0",
   "metadata": {},
   "source": [
    "# 池化层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f50ce0",
   "metadata": {},
   "source": [
    "## 二维最大池化层和平均池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77826f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X,pool_size,mode='max'):\n",
    "    X=X.float()\n",
    "    p_h,p_w=pool_size\n",
    "    Y=torch.zeros(X.shape[0]-p_h+1,X.shape[1]-p_w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=X[i:i+p_h,j:j+p_w].max()\n",
    "            elif mode=='avg':\n",
    "                Y[i,j]=X[i:i+p_h,j:j+p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f84dd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
    "pool2d(X,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2749186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X,(2,2),'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8e958",
   "metadata": {},
   "source": [
    "## 填充和步幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a5e061b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(16,dtype=torch.float).view((1,1,4,4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47f9a50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d=nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7d07ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d=nn.MaxPool2d(3,padding=1,stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8302141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d=nn.MaxPool2d((2,4),padding=(1,2),stride=(2,3))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53caca8e",
   "metadata": {},
   "source": [
    "## 多通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4815b0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.cat((X,X+1),dim=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c16bea15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d=nn.MaxPool2d(3,padding=1,stride=2)\n",
    "pool2d(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
