{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f539aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_ROOT='./S1/CSCL/tangss/Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be0f78",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92dc7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=os.path.join(DATA_ROOT,'aclImdb_v1.tar.gz')\n",
    "if not os.path.exists(os.path.join(DATA_ROOT,'aclImdb')):\n",
    "    print('从压缩包解压...')\n",
    "    with tarfile.open(fname,'r') as f:\n",
    "        f.extractall(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15069373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:05<00:00, 2147.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:05<00:00, 2213.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:05<00:00, 2229.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:06<00:00, 1828.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def read_imdb(folder='train',data_root=\"./S1/CSCL/tangss/Datasets/aclImdb\"):\n",
    "    data=[]\n",
    "    for label in ['pos','neg']:\n",
    "        folder_name=os.path.join(data_root,folder,label)\n",
    "        for file in tqdm(os.listdir(folder_name)):\n",
    "            with open(os.path.join(folder_name,file),'rb') as f:\n",
    "                review=f.read().decode('utf-8').replace('\\n','').lower()\n",
    "                data.append([review,1 if label=='pos' else 0])\n",
    "    random.shuffle(data)\n",
    "    return data\n",
    "train_data,test_data=read_imdb('train'),read_imdb('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8475144",
   "metadata": {},
   "source": [
    "# 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a469607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_imdb(data):\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text.split(' ')]\n",
    "    return [tokenizer(review) for review,_ in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ff3f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('#words in vocab:', 46152)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vocab_imdb(data):\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    counter=collections.Counter([tk for st in tokenized_data for tk in st])\n",
    "    return Vocab.Vocab(counter,min_freq=5)\n",
    "vocab=get_vocab_imdb(train_data)\n",
    "'#words in vocab:',len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a26dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imdb(data,vocab):\n",
    "    max_l=500\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x)>max_l else x+[0]*(max_l-len(x))\n",
    "    tokenized_data=get_tokenized_imdb(data)\n",
    "    features=torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    labels=torch.tensor([score for _,score in data])\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5eb2e",
   "metadata": {},
   "source": [
    "# 创建数据迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00437b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_set=Data.TensorDataset(*preprocess_imdb(train_data,vocab))\n",
    "test_set=Data.TensorDataset(*preprocess_imdb(test_data,vocab))\n",
    "train_iter=Data.DataLoader(train_set,batch_size,shuffle=True)\n",
    "test_iter=Data.DataLoader(test_set,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5b33a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X torch.Size([64, 500]) y: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('#batches:', 391)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X,y in train_iter:\n",
    "    print('X',X.shape,'y:',y.shape)\n",
    "    break\n",
    "'#batches:',len(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c2f21",
   "metadata": {},
   "source": [
    "# 使用循环神经网络的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8ee107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self,vocab,embed_size,num_hiddens,num_layers):\n",
    "        super(BiRNN,self).__init__()\n",
    "        self.embedding=nn.Embedding(len(vocab),embed_size)\n",
    "        # bidirectional设为True即得到双向循环神经⽹络\n",
    "        self.encoder=nn.LSTM(input_size=embed_size,\n",
    "                            hidden_size=num_hiddens,\n",
    "                            num_layers=num_layers,\n",
    "                            bidirectional=True)\n",
    "        # 初始时间步和最终时间步的隐藏状态作为全连接层输⼊\n",
    "        self.decoder=nn.Linear(4*num_hiddens,2)\n",
    "    def forward(self,inputs):\n",
    "        embeddings=self.embedding(inputs.permute(1,0))\n",
    "        outputs,_=self.encoder(embeddings)\n",
    "        encoding=torch.cat((outputs[0],outputs[-1]),-1)\n",
    "        outs=self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27e888c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size,num_hiddens,num_layers=100,100,2\n",
    "net=BiRNN(vocab,embed_size,num_hiddens,num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d316c6f",
   "metadata": {},
   "source": [
    "# 加载预训练的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea6ba4b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glove_vocab=Vocab.GloVe(name='6B',dim=100,cache='./Datasets/glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d9d00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embedding(words,pretrained_vocab):\n",
    "    embed=torch.zeros(len(words),pretrained_vocab.vectors[0].shape[0])\n",
    "    oov_count=0\n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            idx=pretrained_vocab.stoi[word]\n",
    "            embed[i,:]=pretrained_vocab.vectors[idx]\n",
    "        except KeyError:\n",
    "            oov_count+=0\n",
    "    if oov_count>0:\n",
    "        print('there are %d oov words.'%oov_count)\n",
    "    return embed\n",
    "net.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos,glove_vocab))\n",
    "net.embedding.weight.requires_grad=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67db28",
   "metadata": {},
   "source": [
    "# 训练并评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f89755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print('training on ',device)\n",
    "    loss=torch.nn.CrossEntropyLoss()\n",
    "    batch_count=0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start=0.0,0.0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum+=l.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print('epoch %d,loss %.4f,train acc %.3f,test acc %.3f,time %.lf sec'%(epoch+1,train_l_sum/batch_count,train_acc_sum/n,test_acc,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb8a29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net,device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    acc_sum,n=0.0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in data_iter:\n",
    "            if isinstance(net,torch.nn.Module):\n",
    "                net.eval()#评估模式，这会关闭dropout\n",
    "                acc_sum+=(net(X.to(device)).argmax(dim=1)==y.to(device)).float().sum().cpu().item()\n",
    "                net.train()#改回训练模式\n",
    "            else:\n",
    "                if('is_training' in net.__code__.co_varname):\n",
    "                    acc_sum+=(net(X,is_training=False).argmax(dim=1)==y).float().sum().item()\n",
    "            n+=y.shape[0]\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d55be04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1,loss 0.5873,train acc 0.680,test acc 0.803,time 221 sec\n",
      "epoch 2,loss 0.2000,train acc 0.823,test acc 0.841,time 219 sec\n",
      "epoch 3,loss 0.1137,train acc 0.854,test acc 0.851,time 219 sec\n",
      "epoch 4,loss 0.0762,train acc 0.871,test acc 0.840,time 219 sec\n",
      "epoch 5,loss 0.0522,train acc 0.895,test acc 0.855,time 219 sec\n"
     ]
    }
   ],
   "source": [
    "lr,num_epochs=0.01,5\n",
    "optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad,net.parameters()),lr=lr)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eab43c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(net,vocab,sentence):\n",
    "    device=list(net.parameters())[0].device\n",
    "    sentence=torch.tensor([vocab.stoi[word] for word in sentence],device=device)\n",
    "    label=torch.argmax(net(sentence.view((1,-1))),dim=1)\n",
    "    return 'positive' if label.item()==1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dcda7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net,vocab,['this','movie','is','so','great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be32543c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net,vocab,['this','movie','is','bad'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
