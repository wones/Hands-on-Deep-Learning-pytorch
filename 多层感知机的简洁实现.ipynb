{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b5bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import sys\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adbdf03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230752cd",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f9f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_outputs,num_hiddens=784,10,256\n",
    "net=nn.Sequential(\n",
    "    FlattenLayer(),\n",
    "    nn.Linear(num_inputs,num_hiddens),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(num_hiddens,num_outputs),\n",
    ")\n",
    "for param in net.parameters():\n",
    "    init.normal_(param,mean=0,std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13598578",
   "metadata": {},
   "source": [
    "# 读取数据并训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f58d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n=0.0,0\n",
    "    for X,y in data_iter:\n",
    "        acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item()\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac017ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params=None,lr=None,optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n=0.0,0.0,0\n",
    "        for X,y in train_iter:\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y).sum()\n",
    "            \n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "                    \n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params,lr,batch_size)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "                \n",
    "            train_l_sum+=l.item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().item()\n",
    "            n+=y.shape[0]\n",
    "        \n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print('epoch %d,loss %.4f,train acc %.3f,test acc %.3f'%(epoch+1,train_l_sum/n,train_acc_sum/n,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1f6188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss 0.0019,train acc 0.822,test acc 0.831\n",
      "epoch 2,loss 0.0017,train acc 0.843,test acc 0.833\n",
      "epoch 3,loss 0.0016,train acc 0.852,test acc 0.844\n",
      "epoch 4,loss 0.0014,train acc 0.864,test acc 0.853\n",
      "epoch 5,loss 0.0014,train acc 0.870,test acc 0.830\n"
     ]
    }
   ],
   "source": [
    "batch_size=256\n",
    "mnist_train=torchvision.datasets.FashionMNIST(root='./Datasets/FashionMNIST',train=True,download=False,transform=transforms.ToTensor())\n",
    "mnist_test=torchvision.datasets.FashionMNIST(root='./Datasets/FashionMNIST',train=False,download=False,transform=transforms.ToTensor())\n",
    "if sys.platform.startswith('win'):\n",
    "    num_workers=0\n",
    "else:\n",
    "    num_workers=4\n",
    "train_iter=torch.utils.data.DataLoader(mnist_train,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "test_iter=torch.utils.data.DataLoader(mnist_test,batch_size=batch_size,shuffle=False,num_workers=num_workers)\n",
    "\n",
    "loss=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=0.5)\n",
    "num_epochs=5\n",
    "train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,None,None,optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
